{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 项目简介",
   "id": "42ff6536687e9b25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在 MRI 扫描中自动分割胃和肠道。MRI 扫描来自实际的癌症患者，他们在放射治疗期间的不同日期进行了 1-5 次 MRI 扫描",
   "id": "578e4d39270017dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Library*",
   "id": "2bb736fc0b15077e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import rasterio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ],
   "id": "c779a659f25d8727",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "主要库：\n",
    "图像处理：cv2、matplotlib\n",
    "数据划分：sklearn.model_selection\n",
    "深度学习：torch、timm"
   ],
   "id": "ed24b9deaef6d7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Wandb*",
   "id": "f4e2a0fd552ea7d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"\")\n"
   ],
   "id": "3ef9d8d68435e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用Wandb作为实验记录工具（为了安全性 删去了我的AIP KEY）\n",
    "***"
   ],
   "id": "c45c43b0f0c2e2db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *ConFiguration*",
   "id": "c9739055ed55a649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    exp_name      = 'Baselinev2'\n",
    "    comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n",
    "    model_name    = 'Unet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    train_bs      = 128\n",
    "    valid_bs      = train_bs*2\n",
    "    img_size      = [224, 224]\n",
    "    epochs        = 15\n",
    "    lr            = 2e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 3\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "b83472b3a512f3a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "配置类：用于集中管理训练过程中的所有重要参数\n",
    "<br>模型：U-net\n",
    "<br>特征编码器：EfficientNet-B1\n",
    "<br>Learning Rate：CosineAnnealingLR\n"
   ],
   "id": "3663b2c81ba8d286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Reproducibility*",
   "id": "f3103776f3d9a905"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "\n",
    "set_seed(CFG.seed)"
   ],
   "id": "ff22fbd0ea6b29a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "设置随机种子，以确保实验结果的可复现性\n",
    "***"
   ],
   "id": "f41f03f69346fa61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Meta Data*",
   "id": "5af780a5adaa01db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "BASE_PATH = r'D:\\AAA XR\\Se\\archive'",
   "id": "f52e0a62de35ec3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(f'{BASE_PATH}\\\\train.csv')\n",
    "df['segmentation'] = df.segmentation.fillna('')\n",
    "df['rle_len'] = df.segmentation.map(len) # length of each rle mask\n",
    "df['mask_path'] = df.mask_path.str.replace('/png/','/np').str.replace('.png','.npy')\n",
    "\n",
    "df2 = df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index() # rle list of each id\n",
    "df2 = df2.merge(df.groupby(['id'])['rle_len'].agg(sum).to_frame().reset_index()) # total length of all rles of each id\n",
    "\n",
    "df = df.drop(columns=['segmentation', 'class', 'rle_len'])\n",
    "df = df.groupby(['id']).head(1).reset_index(drop=True)\n",
    "df = df.merge(df2, on=['id'])\n",
    "df['empty'] = (df.rle_len==0) # empty masks\n",
    "df.head()"
   ],
   "id": "8cd888d9741ab698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "项目的数据结构和文件内容\n",
    "\n",
    "***"
   ],
   "id": "999cc81e6a58d356"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Class Dsitribution*",
   "id": "5751dfe3b1d9b11b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['empty'].value_counts().plot.bar()",
   "id": "f0ef0baff7575c73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "检查数据分布",
   "id": "19db6049ce962a56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Mask*",
   "id": "18328f583cb33403"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def id2mask(id_):\n",
    "    idf = df[df['id']==id_]\n",
    "    wh = idf[['height','width']].iloc[0]\n",
    "    shape = (wh.height, wh.width, 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n",
    "        cdf = idf[idf['class']==class_]\n",
    "        rle = cdf.segmentation.squeeze()\n",
    "        if len(cdf) and not pd.isna(rle):\n",
    "            mask[..., i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "def rgb2gray(mask):\n",
    "    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n",
    "    gray_mask = pad_mask.argmax(-1)\n",
    "    return gray_mask\n",
    "\n",
    "def gray2rgb(mask):\n",
    "    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n",
    "    return rgb_mask[..., 1:].astype(mask.dtype)"
   ],
   "id": "5ac8e3d79dd4ecee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "这个模块是对mask数据的处理:\n",
    "<br>1.将给定图像的RLE编码解码为像素mask\n",
    "<br>2.将多通道的mask转换为单通道，用于训练输入\n",
    "<br>3.将灰度格式的mask重新转换为多通道 RGB 格式，用于可视化和后处理"
   ],
   "id": "31e29d9c2a5037b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***\n",
   "id": "703b1e28343f3f7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Image*",
   "id": "b0be3093abbc4de1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = np.load(path)\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0\n",
    "    return msk\n",
    "\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#     img = clahe.apply(img)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "\n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ],
   "id": "ed7c338568faed56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.加载图像，同时进行归一化方便输入\n",
    "<br>2.加载mask，同样进行归一化\n",
    "<br>3.显示图像以及可能有的mask（以0.5的透明度）\n",
    "***\n"
   ],
   "id": "e0aba29415ddb086"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *RLE*\n",
   "id": "292ebf751510d523"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ],
   "id": "ff944c9693ca55b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RLE编码（Run-Length Encoding）：用于紧凑表示mask图像的编码格式，编码中记录像素的起始位置和长度（即连续的像素范围）。",
   "id": "798c0263e6afac4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Create Folds*",
   "id": "b5d4d795c82c8f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','empty'])['id'].count())\n",
    "grouped_data = df.groupby(['fold', 'empty'])['id'].count()\n",
    "print(grouped_data)"
   ],
   "id": "73ffebe49e7e5993",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "进行数据集的分层分组交叉验证",
   "id": "58e56a6c7bdd54f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *DataSet*\n",
   "id": "1c68ba2d97c818a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=True, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.img_paths  = df['image_path'].tolist()\n",
    "        self.msk_paths  = df['mask_path'].tolist()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = []\n",
    "        img = load_img(img_path)\n",
    "\n",
    "        if self.label:\n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            msk = np.transpose(msk, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img)"
   ],
   "id": "16dbff693f14c526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "定义一个数据集类，用于为分割任务构建数据加载器\n",
    "<br>主要作用：\n",
    "<br>1.加载图像和mask\n",
    "<br>2.支持数据增强操作\n",
    "<br>3.数据从HWC转为CHW，最后返回tensor"
   ],
   "id": "2616ee73cff17915"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***",
   "id": "72884ed69d3016e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Augmentations*",
   "id": "fd80f0c4fe20616"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        A.OneOf([\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "# #             A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        ], p=0.25),\n",
    "        A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
    "                         min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "        ], p=1.0)\n",
    "}"
   ],
   "id": "6dc8a4a35f289310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用Albumentations库对图像和mask进行预处理和数据增强\n",
    "<br>训练集包括：大小调整、水平翻转、平移缩放、小角度旋转、网格或弹性、随机遮挡\n",
    "<br>验证集仅大小调整"
   ],
   "id": "9afcfd1eb61c23a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***\n",
   "id": "2f38b32a664cd5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *DataLoader*",
   "id": "4f34a0ed8ea58340"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_loaders(fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    if debug:\n",
    "        train_df = train_df.head(32*5).query(\"empty==0\")\n",
    "        valid_df = valid_df.head(32*3).query(\"empty==0\")\n",
    "    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs if not debug else 20,\n",
    "                              num_workers=4, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs if not debug else 20,\n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader"
   ],
   "id": "ca4e7d35054d2925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_loader, valid_loader = prepare_loaders(fold=0, debug=True)",
   "id": "ebea2948d19c290a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imgs, msks = next(iter(train_loader))\n",
    "imgs.size(), msks.size()"
   ],
   "id": "30bc6181784871ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "根据数据集fold构建训练和验证的数据加载器",
   "id": "fd5b9abfae1abe6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Visualization*",
   "id": "4d67d5fe525b5e1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_batch(imgs, msks, size=3):\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx,].permute((1, 2, 0)).numpy()*255.0\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx,].permute((1, 2, 0)).numpy()*255.0\n",
    "        show_img(img, msk)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "19c56b144c9a0d0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_batch(imgs, msks, size=5)",
   "id": "8cb8779e23adcc90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gc\n",
    "gc.collect()"
   ],
   "id": "5a650aa31d74f449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "可视化加载的图像和mask，便于确认是否匹配",
   "id": "47a614842f5bf75a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Model*",
   "id": "8fe28a9b0d5ba15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CFG.backbone,      # choose encoder\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB)\n",
    "        classes=CFG.num_classes,        # model output channels\n",
    "        activation=None,\n",
    "    )\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ],
   "id": "f7e33149ac79290d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "基于SMP实现了U-Net架构",
   "id": "a13999f7d08e1fd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Loss Function*",
   "id": "8e1ab6023ee35d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel')\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.5*BCELoss(y_pred, y_true) + 0.5*TverskyLoss(y_pred, y_true)"
   ],
   "id": "5f6ddbcb7c777cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "定义Loss和评估指标\n",
    "<br>JaccardLoss：交并比\n",
    "<br>DiceLoss：预测与真实区域的重叠\n",
    "<br>BCELoss：二分类交叉熵\n",
    "<br>LovaszLoss：优化JaccardLoss\n",
    "<br>TverskyLoss：类似Dice，允许调整假阴性和假阳性的权重\n",
    "<br>计算DIce和IOU"
   ],
   "id": "edca57617242568d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***",
   "id": "74553004a44bed53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Training Function*",
   "id": "50a83ea63deefa6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss"
   ],
   "id": "24567c64154c4403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "定义训练函数，用于执行训练模型的单个epoch\n",
    "<br>训练模型、支持混合精度训练、动态learning rate调整、更新进度\n",
    "***\n"
   ],
   "id": "34930682d0a31d61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Validation Function*",
   "id": "8fec4339a92bec27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    val_scores = []\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:\n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, val_scores"
   ],
   "id": "cd18cf9b1cabf303",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "定义函数执行模型的单次验证，评估模型在验证集上的性能，包括损失值和评价指标（如 Dice 系数和 IOU 系数）。\n",
    "<br>注：因为这是一个多标签分类任务（胃、大小肠），所以输出层使用sigmoid而非softmax\n",
    "***\n"
   ],
   "id": "8b1b5649fd0bc8c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Run Training*",
   "id": "52d81fdf4154fdcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler,\n",
    "                                           dataloader=train_loader,\n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "\n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader,\n",
    "                                                 device=CFG.device,\n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "        history['Valid Jaccard'].append(val_jaccard)\n",
    "\n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_loss,\n",
    "                   \"Valid Loss\": val_loss,\n",
    "                   \"Valid Dice\": val_dice,\n",
    "                   \"Valid Jaccard\": val_jaccard,\n",
    "                   \"LR\":scheduler.get_last_lr()[0]})\n",
    "\n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_dice >= best_dice:\n",
    "            print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            best_dice    = val_dice\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch   = epoch\n",
    "            run.summary[\"Best Dice\"]    = best_dice\n",
    "            run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "            run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            wandb.save(PATH)\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        print(); print()\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ],
   "id": "f0a7b1c2363bcce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "训练流程、最佳模型保存、性能监控、资源管理\n",
    "***"
   ],
   "id": "a50c1fa48f106966"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Optimizer*",
   "id": "5a0e0f57f58e382e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max,\n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0,\n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "\n",
    "    return scheduler"
   ],
   "id": "b5cc79f03150754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = build_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "scheduler = fetch_scheduler(optimizer)"
   ],
   "id": "4cf3b49839e9acb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "根据任务制定不同的learning rate调整策略：\n",
    "<br>1.调用配置类里定义scheduler\n",
    "<br>2.结合余弦退火和warm restart\n",
    "<br>3.ReduceLROnPlateau：当验证集损失在 patience 个 Epoch 内未改善时，将学习率乘以 factor\n",
    "<br>4.在需要快速收敛时，使用指数衰减\n",
    "<br>5.没有scheduler时，保持固定learning rate\n",
    "<br>6.使用Adam 设置初始学习率和权重衰减"
   ],
   "id": "938b2cbc53afcdf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***",
   "id": "1df8c6465cc6d583"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Training*",
   "id": "98a2eada9e1ebb20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for fold in range(1):\n",
    "    print(f'#'*15)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*15)\n",
    "    run = wandb.init(project=\"uNet S\",\n",
    "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
    "                     group=CFG.comment,\n",
    "                    )\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
    "    model     = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CFG.device,\n",
    "                                  num_epochs=CFG.epochs)\n",
    "    run.finish()\n",
    "    display(ipd.IFrame(run.url, width=1000, height=720))"
   ],
   "id": "875a540a41b6d68a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "完整的训练过程，并使用wandb进行实验追踪",
   "id": "8312571e2b00c91b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## *Prediction*",
   "id": "f7dca1f85b9deaa3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = BuildDataset(df.query(\"fold==0 & empty==0\").sample(frac=1.0), label=False,\n",
    "                            transforms=data_transforms['valid'])\n",
    "test_loader  = DataLoader(test_dataset, batch_size=5,\n",
    "                          num_workers=4, shuffle=False, pin_memory=True)\n",
    "imgs = next(iter(test_loader))\n",
    "imgs = imgs.to(CFG.device, dtype=torch.float)\n",
    "\n",
    "preds = []\n",
    "for fold in range(1):\n",
    "    model = load_model(f\"best_epoch-{fold:02d}.bin\")\n",
    "    with torch.no_grad():\n",
    "        pred = model(imgs)\n",
    "        pred = (nn.Sigmoid()(pred)>0.5).double()\n",
    "    preds.append(pred)\n",
    "\n",
    "imgs  = imgs.cpu().detach()\n",
    "preds = torch.mean(torch.stack(preds, dim=0), dim=0).cpu().detach()\n"
   ],
   "id": "89687d3042564d8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_batch(imgs, preds, size=5)",
   "id": "2617d225ee116fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型预测，包括加载模型、进行推断，以及对测试数据进行可视化。",
   "id": "78ebe6b8f516ad7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
